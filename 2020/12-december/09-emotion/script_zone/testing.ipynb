{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbasecondac27713b0d4da4424a3036238a0ac4095",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------IMPORT----------------------------------------------------------------------------#\n",
    "#dieu\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer , TfidfTransformer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import recall_score , precision_score ,f1_score\n",
    "from sklearn import metrics , svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB, ComplementNB, BernoulliNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#vis\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "#NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords , wordnet as wn\n",
    "from nltk import wordpunct_tokenize , WordNetLemmatizer ,sent_tokenize ,  word_tokenize\n",
    "from nltk.stem import PorterStemmer , LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------DATAFRAME DISPLAY------------------------------------------------------------------#\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.width', None)\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "pd.reset_option(\"^display\") ##Reset display option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------FUNCTIONS--------------------------------------------------------------------#\n",
    "def get_top_n_words(corpus,d,n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     vec.vocabulary_.items()]\n",
    "    if d == \"up\" :\n",
    "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "        return words_freq[:n]\n",
    "    elif d == \"down\" :\n",
    "        words_freq=sorted(words_freq, key = lambda x: x[1], reverse=False)\n",
    "        return words_freq[:n]\n",
    "\n",
    "def tokenize(corpus):\n",
    "    #text = ''.join([ch for ch in text if ch not in dataEF[\"Text\"]])\n",
    "    tokens = nltk.word_tokenize()\n",
    "    lemma = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    # tokens = [lemmatizer.lemmatize(token) for token in tokens] \n",
    "    #OR\n",
    "    # tokens = [lemma.lemmatize(lemma.lemmatize(lemma.lemmatize(w,'v'),'n'),'a')for w in tokens]\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def run_pipes(pipes, splits=10, test_size=0.2, seed=42):  \n",
    "    res = defaultdict(list)\n",
    "    spliter = ShuffleSplit(n_splits=splits, test_size=test_size, random_state=seed)\n",
    "    for idx_train, idx_test in spliter.split(corpus):\n",
    "        for pipe in pipes:\n",
    "            # name of the model\n",
    "            name = \"-\".join([x[0] for x in pipe.steps])\n",
    "            \n",
    "            # extract datasets\n",
    "            X_train = corpus[idx_train]\n",
    "            X_test = corpus[idx_test]\n",
    "            y_train = targets[idx_train]\n",
    "            y_test = targets[idx_test]\n",
    "            \n",
    "            # Learn\n",
    "            start = time()\n",
    "            pipe.fit(X_train, y_train)\n",
    "            fit_time = time() - start\n",
    "            \n",
    "            # predict and save results\n",
    "            y = pipe.predict(X_test)\n",
    "            res[name].append([\n",
    "                fit_time,\n",
    "                f1_score(y_test, y, average = 'micro'),\n",
    "                precision_score(y_test, y, average = 'micro'),\n",
    "                recall_score(y_test, y, average = 'micro')\n",
    "])\n",
    "    return res\n",
    "\n",
    "def print_table(res):\n",
    "    # Compute mean and std\n",
    "    final = {}\n",
    "    for model in res:\n",
    "        arr = np.array(res[model])\n",
    "        final[model] = {\n",
    "            \"Name\" :model,\n",
    "            \"time\" : arr[:, 0].mean().round(2),\n",
    "            \"f1_score\": [arr[:,1].mean().round(5),arr[:,1].std().round(5)],\n",
    "            \"Precision\": arr[: 2].mean().round(5).round(5),\n",
    "            \"Recall\": arr[: 3].mean().round(5).round(5)\n",
    "                    }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(final, orient=\"index\").round(3)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0_pre = pd.read_csv('../data/emotion_final.csv')\n",
    "\n",
    "# exclude = set(string.punctuation) # exclude = punctuation strings\n",
    "# stop_word = stopwords.words('english') # we choosing stop words of english dict\n",
    "# stop_word_punct = stop_word.extend(exclude) # we add strings punctions to stop word dict\n",
    "\n",
    "# df0_pre.tokenized_sents = df0_pre.apply(lambda row: word_tokenize(row['Text']), axis=1) # Tokenization\n",
    "# df0_pre.tokenized_sents = df0_pre.tokenized_sents.apply(lambda x: [item for item in x if item not in stop_word_punct])\n",
    "# df0_pre.tokenized_sents = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df0_pre.tokenized_sents] \n",
    "# df0_pre.tokenized_sents = df0_pre.tokenized_sents.apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "# df0_pre.tokenized_sents = df0_pre.tokenized_sents.apply(lambda x: [porter.stem(y) for y in x]) # Stem every word.\n",
    "# df0_pre.tokenized_sents = df0_pre.tokenized_sents.apply(lambda x: [lancaster.stem(y) for y in x]) # Stem every word.\n",
    "# #delete list in list, **********need to be in one line*********\n",
    "# dz = df0_pre.tokenized_sents\n",
    "# dz = [[' '.join(i)][0] for i in dz]\n",
    "# df0_pre.tokenized_sents = dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = pd.read_csv('../data/kaggle_emotion.csv')\n",
    "\n",
    "# exclude = set(string.punctuation) # exclude = punctuation strings\n",
    "# stop_word = stopwords.words('english') # we choosing stop words of english dict\n",
    "# stop_word_punct = stop_word.extend(exclude) # we add strings punctions to stop word dict\n",
    "\n",
    "# corpus = np.array(df1[\"Text\"])\n",
    "# targets = np.array(df1[\"Emotion\"])\n",
    "# targets = np.array([1 if x == \"sadness\" else 2 if x==\"anger\" else 3 if x==\"love\" else 4 if x==\"surprise\" else 5 if x==\"fear\" \n",
    "# else 6 for x in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/yes_emotion.csv')\n",
    "\n",
    "exclude = set(string.punctuation) # exclude = punctuation strings\n",
    "stop_word = stopwords.words('english') # we choosing stop words of english dict\n",
    "stop_word_punct = stop_word.extend(exclude) # we add strings punctions to stop word dict\n",
    "\n",
    "corpus = np.array(df1['content'])\n",
    "targets = np.array(df1['sentiment'])\n",
    "targets = np.array([1 if x == \"sadness\" else 2 if x ==\"anger\" else 3 if x ==\"love\" else 4 if x ==\"surprise\" else 5 if x ==\"fear\" else 6 if x == 'empty' else 7 if x =='enthusiasm' else 8 if x == 'neutral' else 9 if x == 'worry' else 10 if x == 'fun' else 11 if x == 'hate' else 12 if x == 'happiness' else 13 if x == 'boredom' else 14 for x in targets])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe0 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "pipe1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('svm', SVC()),\n",
    "])\n",
    "pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "pipe3 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svm', LinearSVC()),\n",
    "])\n",
    "pipe4 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svm', SVC()),\n",
    "])\n",
    "pipe5 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logit', LogisticRegression()),\n",
    "])\n",
    "pipe6 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('mult_nb', MultinomialNB()),\n",
    "])\n",
    "pipe7 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('compl_nb', ComplementNB()),\n",
    "])\n",
    "pipe8 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('bern_nb', BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = run_pipes([pipe0, pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7, pipe8], splits=5)\n",
    "# oui2 = print_table(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              Name    time            f1_score  Precision  \\\n",
       "vect-sgd                  vect-sgd    1.25    [0.3218, 0.0022]      0.574   \n",
       "vect-svm                  vect-svm  273.38  [0.34968, 0.00266]     67.362   \n",
       "vect-tfidf-sgd      vect-tfidf-sgd    0.76   [0.3184, 0.00366]      0.432   \n",
       "vect-tfidf-svm      vect-tfidf-svm  174.39  [0.33335, 0.01733]     44.189   \n",
       "vect-tfidf-logit  vect-tfidf-logit   12.91  [0.35065, 0.00427]      3.348   \n",
       "vect-mult_nb          vect-mult_nb    0.42   [0.3076, 0.00188]      0.332   \n",
       "vect-compl_nb        vect-compl_nb    0.41  [0.29007, 0.00385]      0.321   \n",
       "vect-bern_nb          vect-bern_nb    0.40  [0.29905, 0.00356]      0.320   \n",
       "\n",
       "                  Recall  \n",
       "vect-sgd           0.565  \n",
       "vect-svm          67.627  \n",
       "vect-tfidf-sgd     0.431  \n",
       "vect-tfidf-svm    29.690  \n",
       "vect-tfidf-logit   3.497  \n",
       "vect-mult_nb       0.333  \n",
       "vect-compl_nb      0.324  \n",
       "vect-bern_nb       0.324  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>time</th>\n      <th>f1_score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>vect-sgd</th>\n      <td>vect-sgd</td>\n      <td>1.25</td>\n      <td>[0.3218, 0.0022]</td>\n      <td>0.574</td>\n      <td>0.565</td>\n    </tr>\n    <tr>\n      <th>vect-svm</th>\n      <td>vect-svm</td>\n      <td>273.38</td>\n      <td>[0.34968, 0.00266]</td>\n      <td>67.362</td>\n      <td>67.627</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-sgd</th>\n      <td>vect-tfidf-sgd</td>\n      <td>0.76</td>\n      <td>[0.3184, 0.00366]</td>\n      <td>0.432</td>\n      <td>0.431</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-svm</th>\n      <td>vect-tfidf-svm</td>\n      <td>174.39</td>\n      <td>[0.33335, 0.01733]</td>\n      <td>44.189</td>\n      <td>29.690</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-logit</th>\n      <td>vect-tfidf-logit</td>\n      <td>12.91</td>\n      <td>[0.35065, 0.00427]</td>\n      <td>3.348</td>\n      <td>3.497</td>\n    </tr>\n    <tr>\n      <th>vect-mult_nb</th>\n      <td>vect-mult_nb</td>\n      <td>0.42</td>\n      <td>[0.3076, 0.00188]</td>\n      <td>0.332</td>\n      <td>0.333</td>\n    </tr>\n    <tr>\n      <th>vect-compl_nb</th>\n      <td>vect-compl_nb</td>\n      <td>0.41</td>\n      <td>[0.29007, 0.00385]</td>\n      <td>0.321</td>\n      <td>0.324</td>\n    </tr>\n    <tr>\n      <th>vect-bern_nb</th>\n      <td>vect-bern_nb</td>\n      <td>0.40</td>\n      <td>[0.29905, 0.00356]</td>\n      <td>0.320</td>\n      <td>0.324</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "oui2 = print_table(res)\n",
    "oui2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_name = ['Name','Time/ms','F1 Score | Ecart','Precision','Recall']\n",
    "# oui2.colmuns = col_name\n",
    "oui2.rename(columns={'Name':'Name','time':'Time/ms','f1_score':'F1 Score | Ecart','Precision':'Precision','Recall':'Recall'}, inplace=True)\n",
    "oui2.to_csv('yes_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              Name    time            f1_score  Precision  \\\n",
       "vect-sgd                  vect-sgd    1.25    [0.3218, 0.0022]      0.574   \n",
       "vect-svm                  vect-svm  273.38  [0.34968, 0.00266]     67.362   \n",
       "vect-tfidf-sgd      vect-tfidf-sgd    0.76   [0.3184, 0.00366]      0.432   \n",
       "vect-tfidf-svm      vect-tfidf-svm  174.39  [0.33335, 0.01733]     44.189   \n",
       "vect-tfidf-logit  vect-tfidf-logit   12.91  [0.35065, 0.00427]      3.348   \n",
       "vect-mult_nb          vect-mult_nb    0.42   [0.3076, 0.00188]      0.332   \n",
       "vect-compl_nb        vect-compl_nb    0.41  [0.29007, 0.00385]      0.321   \n",
       "vect-bern_nb          vect-bern_nb    0.40  [0.29905, 0.00356]      0.320   \n",
       "\n",
       "                  Recall  \n",
       "vect-sgd           0.565  \n",
       "vect-svm          67.627  \n",
       "vect-tfidf-sgd     0.431  \n",
       "vect-tfidf-svm    29.690  \n",
       "vect-tfidf-logit   3.497  \n",
       "vect-mult_nb       0.333  \n",
       "vect-compl_nb      0.324  \n",
       "vect-bern_nb       0.324  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>time</th>\n      <th>f1_score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>vect-sgd</th>\n      <td>vect-sgd</td>\n      <td>1.25</td>\n      <td>[0.3218, 0.0022]</td>\n      <td>0.574</td>\n      <td>0.565</td>\n    </tr>\n    <tr>\n      <th>vect-svm</th>\n      <td>vect-svm</td>\n      <td>273.38</td>\n      <td>[0.34968, 0.00266]</td>\n      <td>67.362</td>\n      <td>67.627</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-sgd</th>\n      <td>vect-tfidf-sgd</td>\n      <td>0.76</td>\n      <td>[0.3184, 0.00366]</td>\n      <td>0.432</td>\n      <td>0.431</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-svm</th>\n      <td>vect-tfidf-svm</td>\n      <td>174.39</td>\n      <td>[0.33335, 0.01733]</td>\n      <td>44.189</td>\n      <td>29.690</td>\n    </tr>\n    <tr>\n      <th>vect-tfidf-logit</th>\n      <td>vect-tfidf-logit</td>\n      <td>12.91</td>\n      <td>[0.35065, 0.00427]</td>\n      <td>3.348</td>\n      <td>3.497</td>\n    </tr>\n    <tr>\n      <th>vect-mult_nb</th>\n      <td>vect-mult_nb</td>\n      <td>0.42</td>\n      <td>[0.3076, 0.00188]</td>\n      <td>0.332</td>\n      <td>0.333</td>\n    </tr>\n    <tr>\n      <th>vect-compl_nb</th>\n      <td>vect-compl_nb</td>\n      <td>0.41</td>\n      <td>[0.29007, 0.00385]</td>\n      <td>0.321</td>\n      <td>0.324</td>\n    </tr>\n    <tr>\n      <th>vect-bern_nb</th>\n      <td>vect-bern_nb</td>\n      <td>0.40</td>\n      <td>[0.29905, 0.00356]</td>\n      <td>0.320</td>\n      <td>0.324</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "non = pd.read_csv('yes_pre.csv')\n",
    "non\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "oui1          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0              Name  Time/ms F1 Score | Ecart  Precision  Recall\n",
       "0           0          vect-sgd      NaN              NaN      0.777   0.778\n",
       "1           1          vect-svm      NaN              NaN     22.238  22.929\n",
       "2           2    vect-tfidf-sgd      NaN              NaN      0.761   0.773\n",
       "3           3    vect-tfidf-svm      NaN              NaN     11.863   8.183\n",
       "4           4  vect-tfidf-logit      NaN              NaN      1.703   1.833\n",
       "5           5      vect-mult_nb      NaN              NaN      0.627   0.624\n",
       "6           6     vect-compl_nb      NaN              NaN      0.720   0.718\n",
       "7           7      vect-bern_nb      NaN              NaN      0.557   0.552"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Name</th>\n      <th>Time/ms</th>\n      <th>F1 Score | Ecart</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>vect-sgd</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.777</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>vect-svm</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22.238</td>\n      <td>22.929</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>vect-tfidf-sgd</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.761</td>\n      <td>0.773</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>vect-tfidf-svm</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11.863</td>\n      <td>8.183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>vect-tfidf-logit</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.703</td>\n      <td>1.833</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>vect-mult_nb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.627</td>\n      <td>0.624</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>vect-compl_nb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.720</td>\n      <td>0.718</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>vect-bern_nb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.557</td>\n      <td>0.552</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "parser_f() got an unexpected keyword argument 'columns'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-abf40a36f27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# oui2.to_csv('yes_prediction_pipe.csv',index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Time/ms'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'F1 Score | Ecart'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Recall'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0myes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yes_prediction_pipe.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parser_f() got an unexpected keyword argument 'columns'"
     ]
    }
   ],
   "source": [
    "# oui2.to_csv('yes_prediction_pipe.csv',index=False)\n",
    "col_name = ['Name','Time/ms','F1 Score | Ecart','Precision','Recall']\n",
    "yes = pd.read_csv('yes_prediction_pipe.csv',columns = col_name)\n",
    "\n",
    "yes.columns = col_name\n",
    "# yes.to_csv('yes_pre.csv')\n",
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0              Name  Time/ms    F1 Score | Ecart  Precision  \\\n",
       "0           0          vect-sgd     0.50  [0.88658, 0.00343]      0.777   \n",
       "1           1          vect-svm    93.38  [0.78723, 0.00312]     22.238   \n",
       "2           2    vect-tfidf-sgd     0.43  [0.88998, 0.00316]      0.761   \n",
       "3           3    vect-tfidf-svm    48.62  [0.86768, 0.02397]     11.863   \n",
       "4           4  vect-tfidf-logit     5.09  [0.85391, 0.00548]      1.703   \n",
       "5           5      vect-mult_nb     0.27  [0.74534, 0.00501]      0.627   \n",
       "6           6     vect-compl_nb     0.28  [0.87707, 0.00286]      0.720   \n",
       "7           7      vect-bern_nb     0.28  [0.65522, 0.00809]      0.557   \n",
       "\n",
       "   Recall  \n",
       "0   0.778  \n",
       "1  22.929  \n",
       "2   0.773  \n",
       "3   8.183  \n",
       "4   1.833  \n",
       "5   0.624  \n",
       "6   0.718  \n",
       "7   0.552  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Name</th>\n      <th>Time/ms</th>\n      <th>F1 Score | Ecart</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>vect-sgd</td>\n      <td>0.50</td>\n      <td>[0.88658, 0.00343]</td>\n      <td>0.777</td>\n      <td>0.778</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>vect-svm</td>\n      <td>93.38</td>\n      <td>[0.78723, 0.00312]</td>\n      <td>22.238</td>\n      <td>22.929</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>vect-tfidf-sgd</td>\n      <td>0.43</td>\n      <td>[0.88998, 0.00316]</td>\n      <td>0.761</td>\n      <td>0.773</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>vect-tfidf-svm</td>\n      <td>48.62</td>\n      <td>[0.86768, 0.02397]</td>\n      <td>11.863</td>\n      <td>8.183</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>vect-tfidf-logit</td>\n      <td>5.09</td>\n      <td>[0.85391, 0.00548]</td>\n      <td>1.703</td>\n      <td>1.833</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>vect-mult_nb</td>\n      <td>0.27</td>\n      <td>[0.74534, 0.00501]</td>\n      <td>0.627</td>\n      <td>0.624</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>vect-compl_nb</td>\n      <td>0.28</td>\n      <td>[0.87707, 0.00286]</td>\n      <td>0.720</td>\n      <td>0.718</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>vect-bern_nb</td>\n      <td>0.28</td>\n      <td>[0.65522, 0.00809]</td>\n      <td>0.557</td>\n      <td>0.552</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "oui1 = pd.read_csv('../data/kaggle_pre.csv')\n",
    "oui1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-52da46618a2f>, line 9)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-52da46618a2f>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    .columns\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# oui = pd.DataFrame(data=oui2)\n",
    "# col_name = ['Name','Time/ms','F1 Score | Ecart','Precision','Recall']\n",
    "# oui.columns = col_name\n",
    "# oui.to_csv('prediction_pipe.csv')\n",
    "# oui2\n",
    "oui2.to_csv('prediction_pipe.csv',index=False)\n",
    "oui3 = pd.read_csv('prediction_pipe.csv')\n",
    "\n",
    ".columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe0 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "pipe1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('svm', SVC()),\n",
    "])\n",
    "pipe2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('sgd', SGDClassifier()),\n",
    "])\n",
    "pipe3 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svm', LinearSVC()),\n",
    "])\n",
    "pipe4 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('svm', SVC()),\n",
    "])\n",
    "pipe5 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('logit', LogisticRegression()),\n",
    "])\n",
    "pipe6 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('mult_nb', MultinomialNB()),\n",
    "])\n",
    "pipe7 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('compl_nb', ComplementNB()),\n",
    "])\n",
    "pipe8 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('bern_nb', BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run base pipes\n",
    "# res = run_pipes([pipe0, pipe1, pipe2, pipe3, pipe4, pipe5, pipe6, pipe7, pipe8], splits=5)\n",
    "# print_table(res)\n",
    "\n",
    "# \ttime\tf1_score\n",
    "# vect-sgd\t0.64\t[0.887, 0.005]\n",
    "# vect-svm\t91.26\t[0.787, 0.003]\n",
    "# vect-tfidf-sgd\t0.50\t[0.89, 0.003]\n",
    "# vect-tfidf-svml\t0.59\t[0.891, 0.007]\n",
    "# vect-tfidf-svm\t97.59\t[0.845, 0.006]\n",
    "# vect-tfidf-logit\t4.45\t[0.854, 0.006]\n",
    "# vect-mult_nb\t0.25\t[0.745, 0.005]\n",
    "# vect-compl_nb\t0.24\t[0.877, 0.003]\n",
    "# vect-bern_nb\t0.25\t[0.655, 0.008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "    Emotion  Count\n0     anger   2993\n1      fear   2652\n2     happy   7029\n3      love   1641\n4   sadness   6265\n5  surprise    879\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/emotion_final.csv')\n",
    "\n",
    "# print(df1['Emotion'].unique())\n",
    "df_count_emotion = df1.groupby(['Emotion']).size().reset_index(name='Count')\n",
    "print(df_count_emotion) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # exclude = punctuation strings\n",
    "stop_words = stopwords.words('english') # we choosing stop words of english dict\n",
    "stop_words.extend(exclude) # we add strings punctions to stop word dict\n",
    "lemma = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer(\"english\") # we choosing the language english for the stemmization \n",
    "porter = PorterStemmer() \n",
    "lancaster=LancasterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "21454               Melissa stared at her friend in dism     fear\n",
       "21455  Successive state elections have seen the gover...     fear\n",
       "21456               Vincent was irritated but not dismay     fear\n",
       "21457  Kendall-Hume turned back to face the dismayed ...     fear\n",
       "21458                    I am dismayed , but not surpris     fear\n",
       "\n",
       "[21459 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i can go from feeling so hopeless to so damned...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing a minute to post i feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am ever feeling nostalgic about the fireplac...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i am feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21454</th>\n      <td>Melissa stared at her friend in dism</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21455</th>\n      <td>Successive state elections have seen the gover...</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21456</th>\n      <td>Vincent was irritated but not dismay</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21457</th>\n      <td>Kendall-Hume turned back to face the dismayed ...</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21458</th>\n      <td>I am dismayed , but not surpris</td>\n      <td>fear</td>\n    </tr>\n  </tbody>\n</table>\n<p>21459 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "df_oui = pd.read_csv('../data/emotion_final.csv')\n",
    "df_oui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    Text  Emotion\n",
       "0                                  didnt feel humiliated  sadness\n",
       "1      go feeling hopeless damned hopeful around some...  sadness\n",
       "2              im grabbing minute post feel greedy wrong    anger\n",
       "3      ever feeling nostalgic fireplace know still pr...     love\n",
       "4                                        feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "21454                         Melissa stared friend dism     fear\n",
       "21455  Successive state election seen governing party...     fear\n",
       "21456                           Vincent irritated dismay     fear\n",
       "21457        Kendall-Hume turned back face dismayed coup     fear\n",
       "21458                                 I dismayed surpris     fear\n",
       "\n",
       "[21459 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Emotion</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>didnt feel humiliated</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>go feeling hopeless damned hopeful around some...</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im grabbing minute post feel greedy wrong</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ever feeling nostalgic fireplace know still pr...</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>feeling grouchy</td>\n      <td>anger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21454</th>\n      <td>Melissa stared friend dism</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21455</th>\n      <td>Successive state election seen governing party...</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21456</th>\n      <td>Vincent irritated dismay</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21457</th>\n      <td>Kendall-Hume turned back face dismayed coup</td>\n      <td>fear</td>\n    </tr>\n    <tr>\n      <th>21458</th>\n      <td>I dismayed surpris</td>\n      <td>fear</td>\n    </tr>\n  </tbody>\n</table>\n<p>21459 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df_pre = pd.read_csv('../data/emotion_final.csv')\n",
    "df_pre['Text'] = df_pre.apply(lambda row: word_tokenize(row['Text']), axis=1) # Tokenization\n",
    "df_pre['Text'] = df_pre['Text'].apply(lambda x: [item for item in x if item not in stop_words]) # Stop wordization :) coucou anne-laure\n",
    "df_pre['Text'] = [[lemma.lemmatize(word) for word in each if word not in stop_word] for each in df_pre['Text']]  # Lemmization\n",
    "# df_pre['Text'] = df1['Text'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word. with snowball('english')\n",
    "# df_pre['Text'] = df1['Text'].apply(lambda x: [porter.stem(y) for y in x]) # Stem every word. with porter\n",
    "# df_pre['Text'] = df1['Text'].apply(lambda x: [lancaster.stem(y) for y in x]) # Stem every word. with lancaster\n",
    "dz = df_pre['Text']\n",
    "dz = [[' '.join(i)][0] for i in dz] \n",
    "df_pre['Text'] = dz\n",
    "df_pre\n",
    "# df_pre.to_csv('./data/emotion_final_pre.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         tweet_id   sentiment         author  \\\n",
       "0      1956967341       empty     xoshayzers   \n",
       "1      1956967666     sadness      wannamama   \n",
       "2      1956967696     sadness      coolfunky   \n",
       "3      1956967789  enthusiasm    czareaquino   \n",
       "4      1956968416     neutral      xkilljoyx   \n",
       "...           ...         ...            ...   \n",
       "39995  1753918954     neutral  showMe_Heaven   \n",
       "39996  1753919001        love       drapeaux   \n",
       "39997  1753919005        love       JenniRox   \n",
       "39998  1753919043   happiness       ipdaman1   \n",
       "39999  1753919049        love    Alpharalpha   \n",
       "\n",
       "                                                 content  \n",
       "0      tiffanylu know listenin bad habit ear start fr...  \n",
       "1          layin n bed headach ughhhh ... waitin cal ...  \n",
       "2                       fun ceremon ... gloom friday ...  \n",
       "3                                  want hang friend soon  \n",
       "4      dannycastillo we want trad someon houston tick...  \n",
       "...                                                  ...  \n",
       "39995                                      johnlloydtayl  \n",
       "39996                               happ moth day al lov  \n",
       "39997  happ moth 's day momm wom man long 're 'momma ...  \n",
       "39998  niariley wassup beaut follow me peep out my ne...  \n",
       "39999  mopedronin bullet train tokyo gf visit jap sin...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>sentiment</th>\n      <th>author</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1956967341</td>\n      <td>empty</td>\n      <td>xoshayzers</td>\n      <td>tiffanylu know listenin bad habit ear start fr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1956967666</td>\n      <td>sadness</td>\n      <td>wannamama</td>\n      <td>layin n bed headach ughhhh ... waitin cal ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1956967696</td>\n      <td>sadness</td>\n      <td>coolfunky</td>\n      <td>fun ceremon ... gloom friday ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1956967789</td>\n      <td>enthusiasm</td>\n      <td>czareaquino</td>\n      <td>want hang friend soon</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1956968416</td>\n      <td>neutral</td>\n      <td>xkilljoyx</td>\n      <td>dannycastillo we want trad someon houston tick...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>1753918954</td>\n      <td>neutral</td>\n      <td>showMe_Heaven</td>\n      <td>johnlloydtayl</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>1753919001</td>\n      <td>love</td>\n      <td>drapeaux</td>\n      <td>happ moth day al lov</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>1753919005</td>\n      <td>love</td>\n      <td>JenniRox</td>\n      <td>happ moth 's day momm wom man long 're 'momma ...</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>1753919043</td>\n      <td>happiness</td>\n      <td>ipdaman1</td>\n      <td>niariley wassup beaut follow me peep out my ne...</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>1753919049</td>\n      <td>love</td>\n      <td>Alpharalpha</td>\n      <td>mopedronin bullet train tokyo gf visit jap sin...</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# df1 = pd.read_csv('../data/text_emotion.csv')\n",
    "# df1['content'] = df1.apply(lambda row: word_tokenize(row['content']), axis=1) # Tokenization\n",
    "# df1['content'] = df1['content'].apply(lambda x: [item for item in x if item not in stop_word]) # Stop wordization :) coucou anne-laure\n",
    "# # df1['content'] = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df1['Text']]  # Lemmization\n",
    "# # df1['content'] = df1['content'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word. with snowball('english')\n",
    "# df1['content'] = df1['content'].apply(lambda x: [porter.stem(y) for y in x]) # Stem every word. with porter\n",
    "# df1['content'] = df1['content'].apply(lambda x: [lancaster.stem(y) for y in x]) # Stem every word. with lancaster\n",
    "\n",
    "# dz = df1['content']\n",
    "# dz = [[' '.join(i)][0] for i in dz] \n",
    "\n",
    "# df1['content'] = dz\n",
    "df1.to_csv('text_emotion_pre.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Emotion':df1['Emotion'],'Text':df1['Text']}\n",
    "df28 = pd.DataFrame(data=data)\n",
    "df28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stop_sw' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-86e46108d2a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/emotion_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_sw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stop wordization :) coucou anne-laure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df1['Text'] = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df1['Text']]  # Lemmization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stem every word. with snowball('english')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3847\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3848\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-86e46108d2a4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/emotion_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_sw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stop wordization :) coucou anne-laure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df1['Text'] = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df1['Text']]  # Lemmization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stem every word. with snowball('english')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-86e46108d2a4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/emotion_final.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Tokenization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_sw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stop wordization :) coucou anne-laure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# df1['Text'] = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df1['Text']]  # Lemmization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstemmer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Stem every word. with snowball('english')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_sw' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/emotion_final.csv')\n",
    "df1['Text'] = df1.apply(lambda row: word_tokenize(row['Text']), axis=1) # Tokenization\n",
    "df1['Text'] = df1['Text'].apply(lambda x: [item for item in x if item not in stop_sw]) # Stop wordization :) coucou anne-laure\n",
    "# df1['Text'] = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df1['Text']]  # Lemmization\n",
    "df1['Text'] = df1['Text'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word. with snowball('english')\n",
    "df1['Text'] = df1['Text'].apply(lambda x: [porter.stem(y) for y in x]) # Stem every word. with porter\n",
    "df1['Text'] = df1['Text'].apply(lambda x: [lancaster.stem(y) for y in x]) # Stem every word. with lancaster\n",
    "\n",
    "dz = df1['Text']\n",
    "dz = [[' '.join(i)][0] for i in dz] \n",
    "\n",
    "df1['Text'] = dz\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('../data/text_emotion.csv')\n",
    "\n",
    "df2['tokenized_sents'] = df2.apply(lambda row: word_tokenize(row['content']), axis=1) # Tokenization\n",
    "df2['tokenized_sents'] = df2['tokenized_sents'].apply(lambda x: [item for item in x if item not in stop_sw])\n",
    "df2.tokenized_sents = [[lemma.lemmatize(word) for word in each if word not in stop_sw] for each in df2.tokenized_sents] \n",
    "df2['tokenized_sents'] = df2['tokenized_sents'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "df2['tokenized_sents'] = df2['tokenized_sents'].apply(lambda x: [porter.stem(y) for y in x]) # Stem every word.\n",
    "df2['tokenized_sents'] = df2['tokenized_sents'].apply(lambda x: [lancaster.stem(y) for y in x]) # Stem every word.\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df2['tokenized_sents']\n",
    "x = corpus\n",
    "x = [[' '.join(i)][0] for i in x]\n",
    "\n",
    "df2['tokenized_sents'] = x\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'stop_sw' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-573e23a2d209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TF-IDF Vectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mv_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_sw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# TF-IDF Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop_sw' is not defined"
     ]
    }
   ],
   "source": [
    "corpus = np.array(df1['Text'])\n",
    "x = corpus\n",
    "\n",
    "# TF-IDF Vectorizer \n",
    "v_tf = TfidfVectorizer(stop_words=stop_sw, tokenizer=tokenize, ngram_range=(1,2))\n",
    "x_tf = v_tf.fit_transform(x)\n",
    "# TF-IDF Model\n",
    "idf_values = dict(zip(v_tf.get_feature_names(), v_tf.idf_))\n",
    "words_name = v_tf.get_feature_names()\n",
    "\n",
    "print(\"-- TF-IDF vector shape :\",x_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array(df1['Text'])\n",
    "x = corpus\n",
    "\n",
    "cv = CountVectorizer(stop_words=stop_sw, tokenizer=tokenize, ngram_range=(1,2))\n",
    "x_cv = cv.fit_transform(x) ## Count Vectorizer Model\n",
    "print(\"-- Count_Vectorizer shape :\",x_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train pack with TF-IDF Vectorizer \n",
    "x_tf_train, x_tf_test, y_train, y_test = train_test_split(x_tf, y, test_size=0.20, random_state=0)\n",
    "print('-- Training pack TF-IDF:',\"\\n\")\n",
    "print('-- x_tf_train rows :',np.size(x_tf_train))\n",
    "print('-- x_tf_test rows :',np.size(x_tf_test))\n",
    "print('-- ratio in % :', round(np.size(x_tf_test)/(np.size(x_tf_train)+np.size(x_tf_test))*100,2),\"\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array(df2['content'])\n",
    "x = corpus\n",
    "\n",
    "# TF-IDF Vectorizer \n",
    "v_tf = TfidfVectorizer(stop_words=stop_sw, tokenizer=tokenize, ngram_range=(1,2))\n",
    "x_tf = v_tf.fit_transform(x)\n",
    "# TF-IDF Model\n",
    "idf_values = dict(zip(v_tf.get_feature_names(), v_tf.idf_))\n",
    "words_name = v_tf.get_feature_names()\n",
    "\n",
    "print(\"-- TF-IDF vector shape :\",x_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array(df2['content'])\n",
    "x = corpus\n",
    "\n",
    "cv = CountVectorizer(stop_words=stop_sw, tokenizer=tokenize, ngram_range=(1,2))\n",
    "x_cv = cv.fit_transform(x) ## Count Vectorizer Model\n",
    "print(\"-- Count_Vectorizer shape :\",x_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/emotion_final.csv')\n",
    "\n",
    "x = df1.Text\n",
    "y = df1.Emotion\n",
    "\n",
    "freq_top = get_top_n_words(x,\"up\",100)\n",
    "\n",
    "\n",
    "df_up = pd.DataFrame(freq_top, columns =['Word','Number of times'])\n",
    "y_nbr = df_up['Number of times']\n",
    "x_word = df_up['Word']\n",
    "# df_down = pd.DataFrame(freq_down, columns =['Word','Number of times'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 87, 51, 0.5)",
          "line": {
           "color": "rgb(0,0,0)",
           "width": 2.5
          }
         },
         "name": "Le score universitaire pour le transfert de connaissances par pays",
         "text": [
          "feel",
          "and",
          "to",
          "the",
          "of",
          "that",
          "feeling",
          "my",
          "in",
          "it",
          "like",
          "was",
          "so",
          "for",
          "im",
          "but",
          "me",
          "have",
          "is",
          "with",
          "this",
          "am",
          "not",
          "about",
          "be",
          "as",
          "on",
          "you",
          "at",
          "just",
          "when",
          "or",
          "all",
          "more",
          "because",
          "do",
          "can",
          "up",
          "he",
          "really",
          "by",
          "are",
          "very",
          "been",
          "if",
          "know",
          "had",
          "out",
          "her",
          "time",
          "what",
          "myself",
          "how",
          "from",
          "they",
          "little",
          "get",
          "now",
          "will",
          "being",
          "people",
          "would",
          "them",
          "she",
          "want",
          "some",
          "one",
          "an",
          "his",
          "him",
          "who",
          "still",
          "even",
          "think",
          "there",
          "ive",
          "life",
          "we",
          "its",
          "make",
          "bit",
          "something",
          "much",
          "could",
          "love",
          "going",
          "things",
          "no",
          "dont",
          "than",
          "way",
          "too",
          "day",
          "their",
          "into",
          "back",
          "has",
          "go",
          "which",
          "don"
         ],
         "type": "bar",
         "x": [
          "feel",
          "and",
          "to",
          "the",
          "of",
          "that",
          "feeling",
          "my",
          "in",
          "it",
          "like",
          "was",
          "so",
          "for",
          "im",
          "but",
          "me",
          "have",
          "is",
          "with",
          "this",
          "am",
          "not",
          "about",
          "be",
          "as",
          "on",
          "you",
          "at",
          "just"
         ],
         "y": [
          13973,
          12721,
          11835,
          11808,
          6824,
          6540,
          6461,
          5422,
          4679,
          4087,
          3661,
          3279,
          3211,
          3189,
          3055,
          2948,
          2942,
          2887,
          2808,
          2735,
          2685,
          2608,
          2419,
          2385,
          2297,
          2134,
          2077,
          1962,
          1925,
          1839,
          1819,
          1609,
          1504,
          1474,
          1464,
          1349,
          1240,
          1229,
          1208,
          1201,
          1197,
          1169,
          1143,
          1127,
          1096,
          1091,
          1088,
          1083,
          1083,
          1032,
          1021,
          1007,
          978,
          968,
          968,
          960,
          947,
          920,
          910,
          874,
          865,
          847,
          836,
          815,
          811,
          803,
          802,
          800,
          799,
          797,
          792,
          759,
          746,
          744,
          727,
          723,
          694,
          683,
          673,
          656,
          650,
          646,
          643,
          627,
          620,
          616,
          615,
          610,
          596,
          593,
          593,
          558,
          558,
          545,
          544,
          540,
          536,
          513,
          510,
          509
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Fréquence d’apparition des mots "
        },
        "xaxis": {
         "title": {
          "text": "word rank"
         }
        },
        "yaxis": {
         "title": {
          "text": "word frequency"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "\n",
    "# freq = subsample(wrank)\n",
    "# r = np.arange(len(freq))\n",
    "\n",
    "trace = go.Bar(\n",
    "                x = x_word.head(30),\n",
    "                y = y_nbr,\n",
    "                name = \"Le score universitaire pour le transfert de connaissances par pays\",\n",
    "                marker = dict(color = 'rgba(255, 87, 51, 0.5)', line = dict(color ='rgb(0,0,0)',width =2.5)),\n",
    "                text = df_up['Word'])\n",
    "\n",
    "layout = go.Layout(barmode = \"group\",\n",
    "                  title = 'Fréquence d’apparition des mots ',\n",
    "                  yaxis = dict(title = 'word frequency'),\n",
    "                  xaxis = dict(title = 'word rank'))\n",
    "fig = go.Figure(data = trace, layout = layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "name": "Income",
         "type": "bar",
         "x": [
          "happy",
          "sadness",
          "anger",
          "fear",
          "love",
          "surprise"
         ],
         "y": [
          7029,
          6265,
          2993,
          2652,
          1641,
          879
         ]
        }
       ],
       "layout": {
        "barmode": "relative",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Emotions ranked by occurence in Emotion_final"
        },
        "xaxis": {
         "title": {
          "text": "Emotions"
         }
        },
        "yaxis": {
         "title": {
          "text": "Occurence"
         }
        }
       }
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "dftableau = df1\n",
    "ParGroup = dftableau.groupby('Emotion')\n",
    "y1=ParGroup['Emotion'].size().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "trace = go.Bar(\n",
    "            x = y1.index.get_level_values(0).tolist(),                  \n",
    "            y = y1,\n",
    "            name = 'Income',\n",
    "            type = 'bar',\n",
    "                )\n",
    "\n",
    "layout = go.Layout(\n",
    "            xaxis = {'title': 'Emotions'},\n",
    "            yaxis = {'title': 'Occurence'},\n",
    "            barmode = 'relative',\n",
    "            title = 'Emotions ranked by occurence in Emotion_final')\n",
    "\n",
    "fig = go.Figure(data = trace, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'pandas.core.groupby.generic.DataFrameGroupBy' received for the 'x' property of bar\n        Received value: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f155f419c90>\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-bbc0f55f493e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Income'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_bar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg, alignmentgroup, base, basesrc, cliponaxis, constraintext, customdata, customdatasrc, dx, dy, error_x, error_y, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, insidetextanchor, insidetextfont, legendgroup, marker, meta, metasrc, name, offset, offsetgroup, offsetsrc, opacity, orientation, outsidetextfont, r, rsrc, selected, selectedpoints, showlegend, stream, t, text, textangle, textfont, textposition, textpositionsrc, textsrc, texttemplate, texttemplatesrc, tsrc, uid, uirevision, unselected, visible, width, widthsrc, x, x0, xaxis, xcalendar, xperiod, xperiod0, xperiodalignment, xsrc, y, y0, yaxis, ycalendar, yperiod, yperiod0, yperiodalignment, ysrc, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_v\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3085\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3086\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3087\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4802\u001b[0m                 \u001b[0;31m# ### Handle simple property ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4803\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4804\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4805\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4806\u001b[0m                 \u001b[0;31m# Make sure properties dict is initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5146\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5148\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;31m# val is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5143\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_coerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_invalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mvalidate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_scalar_or_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_invalid_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mraise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mvalid_clr_desc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             )\n\u001b[1;32m    289\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'pandas.core.groupby.generic.DataFrameGroupBy' received for the 'x' property of bar\n        Received value: <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f155f419c90>\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/emotion_final.csv')\n",
    "\n",
    "x = df1.groupby('Emotion')\n",
    "\n",
    "trace = go.Bar(\n",
    "            x = x,                  \n",
    "            y = x,\n",
    "            name = 'Income',\n",
    "            type = 'bar',\n",
    "                )\n",
    "\n",
    "layout = go.Layout(\n",
    "            xaxis = {'title': 'Emotions'},\n",
    "            yaxis = {'title': 'Occurence'},\n",
    "            barmode = 'relative',\n",
    "            title = 'Emotions ranked by occurence in Emotion_final')\n",
    "\n",
    "fig = go.Figure(data = trace, layout = layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('../data/kaggle_emotion.csv')\n",
    "\n",
    "\n",
    "emotion_hist = go.Figure(px.histogram(df1, x=\"Emotion\", color= \"Emotion\", title=\"Histogramme Emotion\").update_xaxes(categoryorder =\"total descending\"))\n",
    "emotion_hist.update_layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0.65)',\n",
    "    plot_bgcolor='rgba(0,0,0,0.65)')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "\n    Invalid value of type 'builtins.str' received for the 'x' property of histogram\n        Received value: 'Emotion'\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-d566ff45e9c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m data = go.Histogram(\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Emotion\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/graph_objs/_histogram.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg, alignmentgroup, autobinx, autobiny, bingroup, cumulative, customdata, customdatasrc, error_x, error_y, histfunc, histnorm, hoverinfo, hoverinfosrc, hoverlabel, hovertemplate, hovertemplatesrc, hovertext, hovertextsrc, ids, idssrc, legendgroup, marker, meta, metasrc, name, nbinsx, nbinsy, offsetgroup, opacity, orientation, selected, selectedpoints, showlegend, stream, text, textsrc, uid, uirevision, unselected, visible, x, xaxis, xbins, xcalendar, xsrc, y, yaxis, ybins, ycalendar, ysrc, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_v\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2411\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xaxis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m         \u001b[0m_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, prop, value)\u001b[0m\n\u001b[1;32m   4802\u001b[0m                 \u001b[0;31m# ### Handle simple property ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4803\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4804\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4805\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4806\u001b[0m                 \u001b[0;31m# Make sure properties dict is initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5146\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5148\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5150\u001b[0m         \u001b[0;31m# val is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/plotly/basedatatypes.py\u001b[0m in \u001b[0;36m_set_prop\u001b[0;34m(self, prop, val)\u001b[0m\n\u001b[1;32m   5141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5142\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5143\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_coerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip_invalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mvalidate_coerce\u001b[0;34m(self, v)\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_scalar_or_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_invalid_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/_plotly_utils/basevalidators.py\u001b[0m in \u001b[0;36mraise_invalid_val\u001b[0;34m(self, v, inds)\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m                 \u001b[0mvalid_clr_desc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m             )\n\u001b[1;32m    289\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: \n    Invalid value of type 'builtins.str' received for the 'x' property of histogram\n        Received value: 'Emotion'\n\n    The 'x' property is an array that may be specified as a tuple,\n    list, numpy array, or pandas Series"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../data/emotion_final.csv')\n",
    "\n",
    "\n",
    "emotion_hist = go.Figure(px.histogram(df1, x=\"Emotion\", color= \"Emotion\", title=\"Histogramme Emotion\").update_xaxes(categoryorder =\"total descending\"))\n",
    "emotion_hist.update_layout(\n",
    "    paper_bgcolor='rgba(0,0,0,0.65)',\n",
    "    plot_bgcolor='rgba(0,0,0,0.65)')\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  }
 ]
}